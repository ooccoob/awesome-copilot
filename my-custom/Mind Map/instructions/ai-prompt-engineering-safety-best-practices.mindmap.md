## What / When / Why / How
- What: 面向 Copilot/LLM 的提示工程+安全与负责任 AI 一体化实践与清单。
- When: 设计/评审提示、构建代理流程、上线包含 AI 输出的功能前。
- Why: 提升输出质量/一致性，降低伤害、偏见、泄露与合规风险。
- How: 明确任务/上下文/约束/格式；采用模式（零/少样本、角色、链式思考）；反模式避坑；系统化安全、测试、版本化与文档。

## Key points
- 基础：清晰任务+足够上下文+明确输出格式与范围；使用长度/风格/结构约束。
- 模式：Zero/Few-shot、Role、CoT；按复杂度选择；A/B 迭代验证。
- 反模式：含糊、冗长、注入、过拟合到样例。
- 安全与偏见：红队/对抗测试；安全清单；中立包容措辞；必要时人审。
- 责任与隐私：透明说明、最小化与匿名化、审计日志、合规对齐（Microsoft/Google/OpenAI 原则、NIST/ISO）。
- 安全工程：输入校验与清洗、参数化提示、敏感信息脱敏、输出适度过滤/替代。
- 测试验证：定义质量/安全/一致性指标；回归与自动评估；版本与变更记录。
- 文档与支持：目的/输入输出/限制/示例；问题上报与改进渠道。

## Compact map
- 目标: 高质量+安全+合规
- 提示设计: 清晰/上下文/约束/格式
- 模式: Zero/Few/Role/CoT
- 安全: 红队→缓解→人审
- 隐私: 最小化/加密/留痕
- 测试: 指标/用例/回归
- 运维: 版本/监控/改进

## Example questions (10+)
- 如何把业务规则转为 Few-shot 样例以最小化幻觉？
- 何时选 Role + CoT 而非 Few-shot？
- 我应如何系统地做提示红队并记录缺陷与缓解？
- 动态用户输入如何做提示注入防护与长度限制？
- 输出如何走自动审核（敏感词/安全 API）并在人审失败时降级？
- 建哪些可度量指标来评估“相关性/一致性/安全性”？
- 如何做提示版本化、A/B 与回滚策略？
- 在日志中保留哪些字段可审计又不泄露隐私？
- 怎样构造“安全模板”以复用到多任务场景？
- 如何在 CI 里跑自动化 Evals 与回归基线？
- 何时需要开启链式思考可见性，何时仅要最终答案？

—
Source: d:\mycode\awesome-copilot\instructions\ai-prompt-engineering-safety-best-practices.instructions.md | Generated: {{timestamp}}
