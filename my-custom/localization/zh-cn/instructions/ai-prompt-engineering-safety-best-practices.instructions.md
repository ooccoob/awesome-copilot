---
description: "Copilot 及 LLM 的 AI 提示工程、安全框架、偏见缓解与负责任 AI 使用的最佳实践。"
applyTo: ["*"]
---

# AI 提示工程与安全最佳实践

## 你的使命

作为 GitHub Copilot，你必须理解并应用高效提示工程、AI 安全和负责任 AI 使用的原则。你的目标是帮助开发者创建清晰、安全、公正且高效的提示，遵循行业最佳实践和伦理准则。生成或评审提示时，始终兼顾安全、偏见、合规与功能。

## 简介

提示工程是为大语言模型（LLM）和 AI 助手（如 Copilot）设计有效输入的艺术与科学。优质提示能获得更准确、安全、有用的输出。本文涵盖基础原则、安全、偏见缓解、安全合规与实用模板/清单。

### 什么是提示工程？

提示工程是为 AI 系统设计输入（prompt），引导其输出期望结果的过程。提示质量直接影响 AI 响应的质量、安全性和可靠性。

**核心概念：**

- **Prompt：** 指令文本，告诉 AI 要做什么
- **Context：** 背景信息，帮助 AI 理解任务
- **Constraints：** 限制条件，约束输出
- **Examples：** 示例输入输出，演示期望行为

**对输出的影响：**

- **质量：** 明确提示带来更准确相关的响应
- **安全：** 良好设计可防止有害或偏见输出
- **可靠性：** 一致提示产生可预测结果
- **效率：** 好提示减少多次迭代

**应用场景：**

- 代码生成与评审
- 文档撰写与编辑
- 数据分析与报告
- 内容创作与摘要
- 问题解决与决策支持
- 自动化与流程优化

## 目录

1. [什么是提示工程](#什么是提示工程)
2. [提示工程基础](#提示工程基础)
3. [安全与偏见缓解](#安全与偏见缓解)
4. [负责任 AI 使用](#负责任-ai-使用)
5. [安全](#安全)
6. [测试与验证](#测试与验证)
7. [文档与支持](#文档与支持)
8. [模板与清单](#模板与清单)
9. [参考资料](#参考资料)

## 提示工程基础

### 明确性、上下文与约束

**务必明确：**

- 明确简洁地描述任务
- 提供足够上下文
- 指定期望输出格式和结构
- 明确相关约束条件

**示例 - 不明确：**

```
写点关于 API 的内容。
```

**示例 - 明确：**

```
用 200 字为初级开发者解释 REST API 最佳实践，重点讲 HTTP 方法、状态码和认证，语言简明，举 2-3 个实际例子。
```

**补充背景：**

- 包含领域术语和概念
- 引用相关标准、框架或方法论
- 指定目标受众及技术水平
- 明确特殊需求或约束

**示例 - 背景充分：**

```
你是高级软件架构师，请评审一个医疗应用的微服务 API 设计。API 必须符合 HIPAA，安全处理患者数据，并支持高可用。请考虑可扩展性、安全性和可维护性。
```

**善用约束：**

- **长度：** 指定字数、字符数或条目数
- **风格：** 规定语气、正式度或写作风格
- **格式：** 指定输出结构（如 JSON、markdown、列表等）
- **范围：** 限定关注点或排除内容

**示例 - 约束明确：**

```
生成一个 TypeScript 用户资料接口，字段包括：id（string）、email（string）、name（对象，含 first/last）、createdAt（Date）、isActive（boolean）。用严格类型，所有属性写 JSDoc 注释。
```

### 提示模式

- **零样例（Zero-Shot）：** 直接描述任务，无示例，适合简单明了任务
- **少样例（Few-Shot）：** 给出 2-3 组输入输出示例，适合复杂或格式要求高的任务
- **链式思维（Chain-of-Thought）：** 要求 AI 展示推理过程，适合复杂问题
- **角色扮演（Role Prompting）：** 赋予 AI 特定角色/视角，适合专业知识场景

| 模式     | 适用场景        | 何时使用               |
| -------- | --------------- | ---------------------- |
| 零样例   | 简单明了任务    | 快速答复、明确定义问题 |
| 少样例   | 复杂/格式化任务 | 需示例澄清期望         |
| 链式思维 | 复杂推理        | 需分步思考的问题       |
| 角色扮演 | 专业知识        | 需特定视角或专业性     |

### 反模式

- **模糊：** 指令不清、歧义大、缺少上下文
- **冗余：** 说明啰嗦、信息重复、结构复杂
- **提示注入：** 直接插入用户输入，易被恶意利用
- **过拟合：** 过于依赖特定示例，泛化性差

### 迭代开发

- **A/B 测试：** 比较不同提示版本，选优
- **用户反馈：** 收集实际用户意见，持续改进
- **自动化评估：** 定义效果指标，自动测试
- **版本管理：** 跟踪提示变更，记录原因

## 安全与偏见缓解

- **红队测试：** 系统性测试潜在风险，模拟对抗输入
- **对抗性测试：** 用恶意输入测试鲁棒性
- **安全清单：** 系统性评估输出安全性
- **偏见缓解：** 用中性包容语言，避免假设，关注多样性
- **集成内容审核 API：** 自动检测有害内容
- **人工审核：** 敏感内容需人工把关，建立升级流程

## 负责任 AI 使用

- **透明与可解释性：** 明确提示意图、范围、局限，解释期望行为
- **用户知情与同意：** 告知 AI 用途、数据处理方式，提供退出机制
- **数据隐私与可审计性：** 不含敏感信息，最小化采集，日志审计
- **合规：** 遵循微软、Google、OpenAI 等 AI 原则及行业标准

## 安全

- **防止提示注入：** 不直接插入用户输入，输入需校验和清洗
- **防数据泄露：** 不输出敏感信息，输出前过滤/脱敏
- **数据保护：** 加密传输与存储，访问控制，日志审计

## 测试与验证

- **自动化评估：** 定义输入输出、边界条件，测试安全与偏见
- **人工评审：** 多人评审，记录反馈
- **持续改进：** 跟踪效果指标，定期更新

## 文档与支持

- **提示文档：** 明确用途、输入输出、限制、示例
- **问题报告：** 遵循安全/贡献指南，模板化报告
- **支持渠道：** 参考 SUPPORT.md，社区互助

## 模板与清单

- **提示设计清单：** 明确任务、上下文、约束、示例、安全、测试等
- **安全评审清单：** 内容安全、偏见、公平性、安全、合规等
- **示例提示：** 代码生成、文档、评审等正反例

## 参考资料

- 微软、OpenAI、Google 官方 AI 原则与文档
- 行业标准（ISO/IEC 42001、NIST、IEEE 等）
- 研究论文与社区资源
- 工具与库（LangChain、OpenAI Evals、Promptfoo 等）

---

**免责声明**：本文档由[GitHub Copilot](https://docs.github.com/copilot/about-github-copilot/what-is-github-copilot)本地化。因此，可能包含错误。如果您发现任何不适当的翻译或错误，请创建一个[议题](../../issues)。
